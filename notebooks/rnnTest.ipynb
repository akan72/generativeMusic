{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lexokan\\Dropbox\\R and Python\\generativeMusic\\data\\audio\n"
     ]
    }
   ],
   "source": [
    "#move to data/audio folder from ~/notebooks/\n",
    "%cd ../data/audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from random import shuffle\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob('*.wav')\n",
    "\n",
    "#build spectrograms for conv net\n",
    "spectrograms = []\n",
    "for audio_file in file_list:\n",
    "    sample_rate, samples = wavfile.read(audio_file)\n",
    "    frequencies, times, spectrogram = signal.spectrogram(samples, sample_rate)\n",
    "    np.place(spectrogram, spectrogram == 0, 10**-10) #avoid div by 0 for log\n",
    "    \n",
    "    audio_raw_name = re.search('.+?(?=\\.wav)', audio_file).group(0) #remove .wav extension\n",
    "    \n",
    "    with open('../annotations/meter/' + audio_raw_name + '.meter', 'r') as file:\n",
    "        meter = file.readline()\n",
    "    \n",
    "    spectrograms.append([audio_raw_name, np.log(spectrogram), meter])\n",
    "    \n",
    "#clean spectrograms data\n",
    "invalid_songs = [[],[]]\n",
    "for index, x in enumerate(spectrograms):\n",
    "    if(x[1].shape != (129, 23624)):\n",
    "        invalid_songs[0].append(index)\n",
    "        invalid_songs[1].append(x[0])\n",
    "\n",
    "for i in sorted(invalid_songs[0], reverse= True):\n",
    "    del spectrograms[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def spec_window(times, spectrogram, window):\n",
    "    spectrogram_window = np.zeros((spectrogram.shape[0], math.ceil(spectrogram.shape[1]/window)), dtype = 'float32')\n",
    "    times_window = np.zeros((math.ceil(times.shape[0]/window),), dtype = 'float32')\n",
    "    for i in range(0, spectrogram.shape[1], window):\n",
    "        if (i + window < spectrogram.shape[1]):\n",
    "            spectrogram_window[:,int(i/window)] = np.mean(spectrogram[:, i:i+window], axis= 1)\n",
    "            times_window[int(i/window)] = np.mean(times[i:i+window])\n",
    "        else:\n",
    "            spectrogram_window[:,int(i/window)] = np.mean(spectrogram[:, i:], axis = 1)\n",
    "            times_window[int(i/window)] = np.mean(times[i:])\n",
    "\n",
    "    return times_window, spectrogram_window\n",
    "\n",
    "def spec_plot(times, frequencies, spectrogram, title):\n",
    "    plt.pcolormesh(times, frequencies, np.log(spectrogram))\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "spec_plot(times, frequencies, spectrogram, 'Original Spectrogram')\n",
    "times_conv, spec_conv = spec_window(times, spectrogram, 5)\n",
    "spec_plot(times_conv, frequencies, spec_conv, 'Convolved Spectrogram (5)') #convolved probs wrong term\n",
    "times_conv, spec_conv = spec_window(times, spectrogram, 10)\n",
    "spec_plot(times_conv, frequencies, spec_conv, 'Convolved Spectrogram (10)')\n",
    "times_conv, spec_conv = spec_window(times, spectrogram, 250)\n",
    "spec_plot(times_conv, frequencies, spec_conv, 'Convolved Spectrogram (250)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "spectrograms_conv = copy.deepcopy(spectrograms) #don't want to change original, deepcopy to copy objs in list\n",
    "dummy = np.zeros((spectrograms[0][1].shape[1],), dtype = 'float32')\n",
    "for index, rows in enumerate(spectrograms):\n",
    "    _, spectrograms_conv[index][1] = spec_window(dummy, rows[1], 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e-10 1.0000000e-10 1.0000000e-10 ... 3.3387566e-01 3.0386728e+01\n",
      " 3.9717121e+01]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-5f4065acd419>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS_db\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'log'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lexokan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\librosa\\display.py\u001b[0m in \u001b[0;36mspecshow\u001b[1;34m(data, x_coords, y_coords, x_axis, y_axis, sr, hop_length, fmin, fmax, bins_per_octave, ax, **kwargs)\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[1;31m# Get the x and y coordinates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[0my_coords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__mesh_coords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_coords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mall_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m     \u001b[0mx_coords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__mesh_coords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_coords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mall_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m     \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__check_axes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for i in range(len(spectrograms)):\n",
    "#     print(spectrograms[i][2])\n",
    "print(spectrogram[0])\n",
    "    \n",
    "# Nonnegative Matrix Factorization\n",
    "# x, sr = spectrogram[0]\n",
    "#S = librosa.effects.percussive(spectrogram[0])\n",
    "#S = librosa.decompose.hpss(spectrogram[0])\n",
    "\n",
    "# S_db = librosa.amplitude_to_db(abs(S))\n",
    "\n",
    "# plt.figure(figsize=(15, 5))\n",
    "# librosa.display.specshow(S_db, sr=2000, x_axis='time', y_axis='log')\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spectrograms) * .7 #80\n",
    "\n",
    "def load_data(spec_data):\n",
    "    \n",
    "    x_train = np.array([x[1] for x in spec_data[:80]])\n",
    "    y_train = np.array([x[2] for x in spec_data[:80]])\n",
    "    \n",
    "    x_test = np.array([x[1] for x in spec_data[80:]])\n",
    "    y_test = np.array([x[2] for x in spec_data[80:]])\n",
    "    \n",
    "    #print(x_train.shape)\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "shuffle(spectrograms_conv) #shuffle spectrogram data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (80, 129, 158, 1)\n",
      "80 train samples\n",
      "x_test shape: (80, 129, 158, 1)\n",
      "34 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "num_classes = 4\n",
    "epochs = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_x, img_y = spectrograms_conv[0][1].shape\n",
    "\n",
    "# load the spectrogram data\n",
    "(x_train, y_train), (x_test, y_test) = load_data(spectrograms_conv)\n",
    "\n",
    "n_train = x_train.shape[0]\n",
    "n_test = x_test.shape[0]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler.fit(x_train.reshape(x_train.shape[0]*img_x, img_y))\n",
    "# reshape the data into a 4D tensor - (sample_number, x_img_size, y_img_size, num_channels)\n",
    "# RGB colour images would have 3, spectrogram data has 1\n",
    "x_train = scaler.transform(x_train.reshape(x_train.shape[0]*img_x, img_y)).reshape((x_train.shape[0],img_x, img_y,1))\n",
    "\n",
    "scaler.fit(x_test.reshape(x_test.shape[0]*img_x, img_y))\n",
    "x_test = scaler.transform(x_test.reshape(x_test.shape[0]*img_x, img_y)).reshape((x_test.shape[0],img_x, img_y,1))\n",
    "\n",
    "\n",
    "input_shape = (img_x, img_y, 1)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print('x_test shape:', x_train.shape)\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices - this is for use in the\n",
    "# categorical_crossentropy loss below\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = tensorflow.keras.utils.to_categorical(le.transform(y_train), num_classes)\n",
    "y_test = tensorflow.keras.utils.to_categorical(le.transform(y_test), num_classes)\n",
    "\n",
    "#del spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 34 samples\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 54s 678ms/step - loss: 1.4534 - acc: 0.2750 - val_loss: 1.3862 - val_acc: 0.2647\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 1.4422 - acc: 0.3000 - val_loss: 1.3964 - val_acc: 0.2059\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.4017 - acc: 0.3750 - val_loss: 1.3865 - val_acc: 0.2647\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.2650 - acc: 0.4625 - val_loss: 1.3700 - val_acc: 0.2647\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 1.0707 - acc: 0.6000 - val_loss: 1.4827 - val_acc: 0.2941\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.6919 - acc: 0.7875 - val_loss: 2.8788 - val_acc: 0.2059\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 0.3847 - acc: 0.8500 - val_loss: 2.4231 - val_acc: 0.1765\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.1145 - acc: 0.9750 - val_loss: 3.8003 - val_acc: 0.1471\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.0713 - acc: 0.9875 - val_loss: 3.4303 - val_acc: 0.2353\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.0187 - acc: 1.0000 - val_loss: 3.6544 - val_acc: 0.2353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a880fc8ac8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(24, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "class AccuracyHistory(tensorflow.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "\n",
    "history = AccuracyHistory()\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3.654443158822901\n",
      "Test accuracy: 0.23529411764705882\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 11), history.acc)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "[ 1. 18.]\n",
      "[[0.   0.  ]\n",
      " [0.25 0.25]\n",
      " [0.5  0.5 ]\n",
      " [1.   1.  ]]\n",
      "[[1.5 0. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = np.array([[-1, 2], [-0.5, 6], [0, 10], [1, 18]])\n",
    "scaler = MinMaxScaler()\n",
    "print(scaler.fit(data))\n",
    "print(scaler.data_max_)\n",
    "print(scaler.transform(data))\n",
    "print(scaler.transform([[2, 2]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
